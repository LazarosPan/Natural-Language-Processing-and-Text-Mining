{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eaec627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert order: ['BertExpert', 'RobertaExpert', 'QuoraDistilExpert', 'CrossEncExpert', 'LRFeatureExpert', 'XGBFeatureExpert', 'LGBMFeatureExpert', 'KNNFeatureExpert', 'RFFeatureExpert', 'SVMFeatureExpert']\n",
      "Loaded cached predictions: (323613, 10) (40710, 10)\n",
      "Grid-search on subsets: ['BertExpert+RobertaExpert+CrossEncExpert+SVMFeatureExpert', 'BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert', 'BertExpert+RobertaExpert+LGBMFeatureExpert', 'BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert+SVMFeatureExpert', 'BertExpert+RobertaExpert', 'BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert', 'BertExpert+RobertaExpert+CrossEncExpert+XGBFeatureExpert', 'BertExpert+RobertaExpert+CrossEncExpert', 'BertExpert+RobertaExpert+CrossEncExpert+LRFeatureExpert', 'BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert+SVMFeatureExpert']\n",
      "\n",
      "=== subset=BertExpert+RobertaExpert+CrossEncExpert+SVMFeatureExpert (4 experts) ===\n",
      "  TRAIN lr=1e-03  ep=35   LL=0.1009  time=41.0s\n",
      "  TRAIN lr=5e-03  ep=17   LL=0.1008  time=22.3s\n",
      "  TRAIN lr=1e-02  ep=11   LL=0.1008  time=16.5s\n",
      "  TRAIN lr=5e-02  ep=4    LL=0.1008  time=9.3s\n",
      "\n",
      "=== subset=BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert (6 experts) ===\n",
      "  TRAIN lr=1e-03  ep=1    LL=0.4156  time=6.0s\n",
      "  TRAIN lr=5e-03  ep=1    LL=0.6554  time=6.4s\n",
      "  TRAIN lr=1e-02  ep=1    LL=0.7464  time=6.0s\n",
      "  TRAIN lr=5e-02  ep=1    LL=0.8201  time=6.1s\n",
      "\n",
      "=== subset=BertExpert+RobertaExpert+LGBMFeatureExpert (3 experts) ===\n",
      "  TRAIN lr=1e-03  ep=6    LL=0.1184  time=11.3s\n",
      "  TRAIN lr=5e-03  ep=2    LL=0.1193  time=7.2s\n",
      "  TRAIN lr=1e-02  ep=1    LL=0.1273  time=6.1s\n",
      "  TRAIN lr=5e-02  ep=1    LL=0.2364  time=6.1s\n",
      "\n",
      "=== subset=BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert+SVMFeatureExpert (8 experts) ===\n",
      "  TRAIN lr=1e-03  ep=1    LL=0.3793  time=6.2s\n",
      "  TRAIN lr=5e-03  ep=1    LL=0.7111  time=6.2s\n",
      "  TRAIN lr=1e-02  ep=1    LL=0.7626  time=6.1s\n",
      "  TRAIN lr=5e-02  ep=1    LL=0.8240  time=6.2s\n",
      "\n",
      "=== subset=BertExpert+RobertaExpert (2 experts) ===\n",
      "  TRAIN lr=1e-03  ep=8    LL=0.1009  time=13.2s\n",
      "  TRAIN lr=5e-03  ep=4    LL=0.1009  time=9.3s\n",
      "  TRAIN lr=1e-02  ep=7    LL=0.1008  time=12.3s\n",
      "  TRAIN lr=5e-02  ep=2    LL=0.1008  time=7.2s\n",
      "\n",
      "=== subset=BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert (5 experts) ===\n",
      "  TRAIN lr=1e-03  ep=1    LL=0.2358  time=6.1s\n",
      "  TRAIN lr=5e-03  ep=1    LL=0.6728  time=6.2s\n",
      "  TRAIN lr=1e-02  ep=1    LL=0.7181  time=6.2s\n",
      "  TRAIN lr=5e-02  ep=1    LL=0.8146  time=6.2s\n",
      "\n",
      "=== subset=BertExpert+RobertaExpert+CrossEncExpert+XGBFeatureExpert (4 experts) ===\n",
      "  TRAIN lr=1e-03  ep=33   LL=0.1008  time=38.7s\n",
      "  TRAIN lr=5e-03  ep=15   LL=0.1008  time=20.7s\n",
      "  TRAIN lr=1e-02  ep=11   LL=0.1007  time=16.3s\n",
      "  TRAIN lr=5e-02  ep=6    LL=0.1007  time=11.4s\n",
      "\n",
      "=== subset=BertExpert+RobertaExpert+CrossEncExpert (3 experts) ===\n",
      "  TRAIN lr=1e-03  ep=33   LL=0.1008  time=38.8s\n",
      "  TRAIN lr=5e-03  ep=18   LL=0.1008  time=23.7s\n",
      "  TRAIN lr=1e-02  ep=11   LL=0.1008  time=16.3s\n",
      "  TRAIN lr=5e-02  ep=4    LL=0.1007  time=9.1s\n",
      "\n",
      "=== subset=BertExpert+RobertaExpert+CrossEncExpert+LRFeatureExpert (4 experts) ===\n",
      "  TRAIN lr=1e-03  ep=34   LL=0.1009  time=40.2s\n",
      "  TRAIN lr=5e-03  ep=13   LL=0.1008  time=18.5s\n",
      "  TRAIN lr=1e-02  ep=13   LL=0.1008  time=18.5s\n",
      "  TRAIN lr=5e-02  ep=3    LL=0.1008  time=8.2s\n",
      "\n",
      "=== subset=BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert+SVMFeatureExpert (7 experts) ===\n",
      "  TRAIN lr=1e-03  ep=1    LL=0.2690  time=6.2s\n",
      "  TRAIN lr=5e-03  ep=1    LL=0.6883  time=6.2s\n",
      "  TRAIN lr=1e-02  ep=1    LL=0.7403  time=6.2s\n",
      "  TRAIN lr=5e-02  ep=1    LL=0.8151  time=6.1s\n",
      "Wrote grid_search.csv\n",
      "\n",
      ">>> Retraining TOP-10 gates on full Train+Valid…\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/gates/moe_BertExpert+RobertaExpert+CrossEncExpert+XGBFeatureExpert_idxs.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 175\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rank, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(top10.itertuples(index=\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[32m1\u001b[39m):\n\u001b[32m    174\u001b[39m     subset, lr, best_ep, _ = row\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     idxs = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../models/gates/moe_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_idxs.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     subset_exps = [experts[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idxs]\n\u001b[32m    177\u001b[39m     P_tv_s = P_tv[:, idxs]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:454\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    455\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../models/gates/moe_BertExpert+RobertaExpert+CrossEncExpert+XGBFeatureExpert_idxs.npy'"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────\n",
    "# 4_GS_models.ipynb · Grid-Search over LR on Top-10 MoE subsets\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "\n",
    "%run setup.py\n",
    "import time, numpy as np, torch, pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import log_loss\n",
    "from itertools import combinations\n",
    "\n",
    "from src.pretrained_models import (\n",
    "    save_gate, load_gate, _subset_key, MoEClassifier\n",
    ")\n",
    "from src.logs import log_event, LogKind\n",
    "\n",
    "DEVICE    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "CACHE_DIR = Path(\"../models/pred_cache\")\n",
    "GS_DIR    = Path(\"../models/gates/grid_search\")          # *one* flat folder\n",
    "GS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── search‐space & early-stopping\n",
    "PATIENCE  = 5\n",
    "MAX_EPOCH = 200\n",
    "LR_VALUES = [1e-3, 5e-3, 1e-2, 5e-2]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1) Re-create *names* of experts in the SAME order used in 04_models.ipynb\n",
    "#    but with tiny dummy objects to avoid GPU/CPU blow-up\n",
    "# ---------------------------------------------------------------------------\n",
    "from src.custom_models import (\n",
    "    LRFeatureExpert, XGBFeatureExpert, LGBMFeatureExpert,\n",
    "    KNNFeatureExpert, RFFeatureExpert, SVMFeatureExpert\n",
    ")\n",
    "# helper to build a dummy carrying the desired class name\n",
    "def dummy(cls):\n",
    "    return type(cls.__name__, (), {})()\n",
    "\n",
    "dummy_hf_names = [\"BertExpert\", \"RobertaExpert\", \"XLNetExpert\",\n",
    "                  \"QuoraDistilExpert\", \"CrossEncExpert\"]\n",
    "\n",
    "# is XLNet cached? If not, drop it so indices stay consistent\n",
    "have_xlnet = (CACHE_DIR/\"train_XLNetExpert.npy\").exists()\n",
    "if not have_xlnet:\n",
    "    dummy_hf_names.remove(\"XLNetExpert\")\n",
    "\n",
    "hf_dummies   = [type(n, (), {})() for n in dummy_hf_names]\n",
    "feat_classes = [\n",
    "    LRFeatureExpert, XGBFeatureExpert, LGBMFeatureExpert,\n",
    "    KNNFeatureExpert, RFFeatureExpert, SVMFeatureExpert\n",
    "]\n",
    "feat_dummies = [dummy(c) for c in feat_classes]\n",
    "\n",
    "experts = hf_dummies + feat_dummies     # TOTAL order identical to 04_models\n",
    "K       = len(experts)\n",
    "print(\"Expert order:\", [e.__class__.__name__ for e in experts])\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2) Load splits & cached probability matrices\n",
    "# ---------------------------------------------------------------------------\n",
    "DATA      = Path(\"../data/splits\")\n",
    "train_df  = pd.read_csv(DATA/\"train.csv\").dropna(subset=[\"question1\",\"question2\"])\n",
    "valid_df  = pd.read_csv(DATA/\"valid.csv\").dropna(subset=[\"question1\",\"question2\"])\n",
    "\n",
    "y_tr      = train_df.is_duplicate.values.astype(int)\n",
    "y_val     = valid_df.is_duplicate.values.astype(int)\n",
    "\n",
    "# cached .npy → column-stack\n",
    "pred_tr   = sorted(CACHE_DIR.glob(\"train_*.npy\"))\n",
    "pred_val  = sorted(CACHE_DIR.glob(\"valid_*.npy\"))\n",
    "assert len(pred_tr) == len(pred_val) == K, \"prediction cache incomplete\"\n",
    "\n",
    "P_tr  = np.column_stack([np.load(f, mmap_mode=\"r\") for f in pred_tr]).astype(\"float32\")\n",
    "P_val = np.column_stack([np.load(f, mmap_mode=\"r\") for f in pred_val]).astype(\"float32\")\n",
    "print(\"Loaded cached predictions:\", P_tr.shape, P_val.shape)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3) Collect Top-10 subsets (from previous tuning)\n",
    "# ---------------------------------------------------------------------------\n",
    "top_idxs = []\n",
    "for idx_path in Path(\"../models/gates\").rglob(\"moe_*_idxs.npy\"):\n",
    "    key = idx_path.stem[len(\"moe_\"):-len(\"_idxs\")]\n",
    "    gate = idx_path.parent / f\"gate_{key}_retrained.pt\"\n",
    "    if gate.exists():\n",
    "        top_idxs.append((key, tuple(np.load(idx_path))))\n",
    "top_idxs = top_idxs[:10]        # keep at most 10\n",
    "print(\"Grid-search on subsets:\", [k for k,_ in top_idxs])\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4) Helper: fit gate with early-stop entirely on GPU tensors\n",
    "# ---------------------------------------------------------------------------\n",
    "def fit_es(subset_exps, P_tr_s, P_val_s, y_tr, y_val, lr):\n",
    "    moe      = MoEClassifier(subset_exps, lr=lr, epochs=MAX_EPOCH)\n",
    "    best_ll  = float(\"inf\"); stale = 0; best_ep = 0\n",
    "\n",
    "    ds      = TensorDataset(\n",
    "        torch.tensor(P_tr_s, dtype=torch.float32, device=DEVICE),\n",
    "        torch.tensor(y_tr,   dtype=torch.float32, device=DEVICE)\n",
    "    )\n",
    "    loader  = DataLoader(ds, batch_size=1024, shuffle=True)\n",
    "\n",
    "    P_val_s_t = torch.tensor(P_val_s, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    for ep in range(1, MAX_EPOCH+1):\n",
    "        for xb, yb in loader:\n",
    "            pred  = (moe.gate(xb) * xb).sum(1).clamp(0,1)\n",
    "            loss  = moe.loss_fn(pred, yb)\n",
    "            moe.opt.zero_grad(); loss.backward(); moe.opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            vpred = (moe.gate(P_val_s_t) * P_val_s_t).sum(1).cpu().numpy()\n",
    "        vll = log_loss(y_val, vpred)\n",
    "\n",
    "        if vll + 1e-4 < best_ll:\n",
    "            best_ll, stale, best_ep = vll, 0, ep\n",
    "        else:\n",
    "            stale += 1\n",
    "            if stale >= PATIENCE:\n",
    "                break\n",
    "    return best_ll, best_ep, moe\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5) Grid-search loop  (skip trial if ckpt already exists)\n",
    "# ---------------------------------------------------------------------------\n",
    "records = []\n",
    "for key, idxs in top_idxs:\n",
    "    subset_exps = [experts[i] for i in idxs]\n",
    "    P_tr_s, P_val_s = P_tr[:, idxs], P_val[:, idxs]\n",
    "\n",
    "    print(f\"\\n=== subset={key} ({len(idxs)} experts) ===\")\n",
    "    for lr in LR_VALUES:\n",
    "        ckpt_glob = GS_DIR / f\"gate_{key}_lr{lr:.0e}_ep*.pt\"\n",
    "        pre = list(GS_DIR.glob(ckpt_glob.name))\n",
    "        if pre:\n",
    "            # just read epoch from filename & eval LL\n",
    "            ep = int(pre[0].stem.split(\"_ep\")[-1])\n",
    "            moe = load_gate(subset_exps, pre[0])\n",
    "            with torch.no_grad():\n",
    "                vpred = (moe.gate(torch.tensor(P_val_s, dtype=torch.float32,\n",
    "                                               device=DEVICE)) * torch.tensor(P_val_s, dtype=torch.float32,\n",
    "                                                                              device=DEVICE)).sum(1).cpu().numpy()\n",
    "            vll = log_loss(y_val, vpred)\n",
    "            print(f\"  SKIP lr={lr:.0e}  ep={ep}  LL={vll:.4f}\")\n",
    "        else:\n",
    "            t0  = time.time()\n",
    "            vll, ep, moe = fit_es(subset_exps, P_tr_s, P_val_s, y_tr, y_val, lr)\n",
    "            torch.save(moe.gate.state_dict(),\n",
    "                       GS_DIR / f\"gate_{key}_lr{lr:.0e}_ep{ep}.pt\")\n",
    "            print(f\"  TRAIN lr={lr:.0e}  ep={ep:<3}  LL={vll:.4f}  time={time.time()-t0:.1f}s\")\n",
    "\n",
    "        records.append((key, lr, ep, vll))\n",
    "        log_event(LogKind.GATE, model=f\"GridGate_{key}\",\n",
    "                  phase=\"tune\", lr=lr, best_epoch=ep,\n",
    "                  valid_log_loss=round(vll,4))\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 6) Save grid-search table\n",
    "# ---------------------------------------------------------------------------\n",
    "df = pd.DataFrame(records, columns=[\"subset\",\"lr\",\"best_epoch\",\"valid_log_loss\"])\n",
    "metric_dir = Path(\"metric_logs\"); metric_dir.mkdir(exist_ok=True)\n",
    "df.to_csv(metric_dir/\"grid_search.csv\", index=False)\n",
    "print(\"Wrote grid_search.csv\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 7) Retrain TOP-10 gates on Train+Valid with best (lr,epoch)\n",
    "# ---------------------------------------------------------------------------\n",
    "top10 = df.nsmallest(10, \"valid_log_loss\")\n",
    "P_tv  = np.vstack([P_tr, P_val]).astype(\"float32\")\n",
    "y_tv  = np.concatenate([y_tr, y_val])\n",
    "\n",
    "final_rows = []\n",
    "print(\"\\n>>> Retraining TOP-10 gates on full Train+Valid…\")\n",
    "for rank, row in enumerate(top10.itertuples(index=False), 1):\n",
    "    subset, lr, best_ep, _ = row\n",
    "    idxs = np.load(f\"../models/gates/moe_{subset}_idxs.npy\")\n",
    "    subset_exps = [experts[i] for i in idxs]\n",
    "    P_tv_s = P_tv[:, idxs]\n",
    "\n",
    "    moe = MoEClassifier(subset_exps, lr=lr, epochs=int(best_ep))\n",
    "    tv_ds = TensorDataset(\n",
    "        torch.tensor(P_tv_s, dtype=torch.float32, device=DEVICE),\n",
    "        torch.tensor(y_tv,   dtype=torch.float32, device=DEVICE)\n",
    "    )\n",
    "    tv_loader = DataLoader(tv_ds, batch_size=1024, shuffle=True)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for ep in range(1, int(best_ep)+1):\n",
    "        for xb, yb in tv_loader:\n",
    "            pred = (moe.gate(xb) * xb).sum(1).clamp(0,1)\n",
    "            loss = moe.loss_fn(pred, yb)\n",
    "            moe.opt.zero_grad(); loss.backward(); moe.opt.step()\n",
    "    dur = time.time()-t0\n",
    "\n",
    "    ckpt = GS_DIR / f\"gate_{subset}_final.pt\"\n",
    "    save_gate(moe, ckpt)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        full_pred = (moe.gate(torch.tensor(P_tv_s, dtype=torch.float32,\n",
    "                                           device=DEVICE)) * torch.tensor(P_tv_s, dtype=torch.float32,\n",
    "                                                                          device=DEVICE)).sum(1).cpu().numpy()\n",
    "    tv_ll = log_loss(y_tv, full_pred)\n",
    "\n",
    "    final_rows.append({\n",
    "        \"rank\": rank, \"subset\": subset, \"lr\": lr,\n",
    "        \"epochs\": best_ep, \"train_valid_LL\": round(tv_ll,6),\n",
    "        \"time_s\": round(dur,2), \"checkpoint\": ckpt.name\n",
    "    })\n",
    "\n",
    "    log_event(LogKind.GATE, model=f\"FinalGate_{subset}\",\n",
    "              phase=\"retrain\", lr=lr, best_epoch=best_ep,\n",
    "              valid_log_loss=round(tv_ll,6))\n",
    "\n",
    "    print(f\"[{rank}/10] {subset:<45}  lr={lr:.0e}  ep={best_ep:<3}  TV-LL={tv_ll:.4f}\")\n",
    "\n",
    "pd.DataFrame(final_rows)\\\n",
    "  .to_csv(metric_dir/\"grid_search_final.csv\", index=False)\n",
    "print(\"\\nSaved grid_search_final.csv with final Train+Valid metrics\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
