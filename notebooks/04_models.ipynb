{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e4bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x730513bd5d30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────\n",
    "# 04_models.ipynb  ·  Mixture‐of‐Experts training & automated tuning\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# 0) Ensure src/ is on PYTHONPATH\n",
    "%run setup.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "# need to delete corrupted cache files\n",
    "import shutil  \n",
    "\n",
    "from src.logs import log_event, LogKind\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 13\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081434f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Load train/valid splits (no changes)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "DATA_DIR = Path(\"../data/splits\")\n",
    "train_df = pd.read_csv(DATA_DIR / \"train.csv\").dropna(subset=[\"question1\", \"question2\"])\n",
    "valid_df = pd.read_csv(DATA_DIR / \"valid.csv\").dropna(subset=[\"question1\", \"question2\"])\n",
    "\n",
    "pairs_tr  = list(zip(train_df.question1, train_df.question2))\n",
    "y_tr      = train_df.is_duplicate.values.astype(int)\n",
    "pairs_val = list(zip(valid_df.question1, valid_df.question2))\n",
    "y_val     = valid_df.is_duplicate.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a386e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Ensure necessary directories exist\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "PRETRAINED_DIR = Path(\"../models/pretrained\")\n",
    "CUSTOM_DIR     = Path(\"../models/custom\")\n",
    "FEATURES_DIR   = Path(\"../models/features\")\n",
    "GATE_DIR       = Path(\"../models/gates\")\n",
    "CACHE_DIR      = Path(\"../models/pred_cache\")   # <-- new centralized cache\n",
    "\n",
    "for d in [PRETRAINED_DIR, CUSTOM_DIR, FEATURES_DIR, GATE_DIR, CACHE_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "437514f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749018606.822064   39987 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749018606.824358   39987 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749018606.830109   39987 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749018606.830119   39987 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749018606.830119   39987 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749018606.830120   39987 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Import all experts\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "from src.pretrained_models import (\n",
    "    BertExpert,\n",
    "    RobertaExpert,\n",
    "    XLNetExpert,\n",
    "    QuoraDistilExpert,\n",
    "    CrossEncExpert,\n",
    "    MoEClassifier,\n",
    "    get_predictions,\n",
    ")\n",
    "from src.custom_models import (\n",
    "    LRFeatureExpert,\n",
    "    XGBFeatureExpert,\n",
    "    LGBMFeatureExpert,\n",
    "    KNNFeatureExpert,\n",
    "    RFFeatureExpert,\n",
    "    SVMFeatureExpert,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5437f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initializing classical feature-based experts…\n",
      "   * LRFeatureExpert pickle found—skipping training.\n",
      "   * XGBFeatureExpert pickle found—skipping training.\n",
      "   * LGBMFeatureExpert pickle found—skipping training.\n",
      "   * KNNFeatureExpert pickle found—skipping training.\n",
      "   * RFFeatureExpert pickle found—skipping training.\n",
      "   * SVMFeatureExpert pickle found—skipping training.\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Instantiate & fit feature-based experts if not already fit\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\">>> Initializing classical feature-based experts…\")\n",
    "\n",
    "# We need qid1/qid2 in train_df for QuoraDistilExpert.fit(...) and for build_features(...) in custom experts\n",
    "meta = pd.read_csv(\"../data/processed/question_meta.csv\")\n",
    "rev  = {q: i for i, q in enumerate(meta.question)}\n",
    "train_df = train_df.assign(\n",
    "    qid1=lambda d: d.question1.map(rev).astype(int),\n",
    "    qid2=lambda d: d.question2.map(rev).astype(int),\n",
    ")\n",
    "\n",
    "# Loop through each custom‐expert class at once\n",
    "feature_expert_classes = [\n",
    "    LRFeatureExpert,\n",
    "    XGBFeatureExpert,\n",
    "    LGBMFeatureExpert,\n",
    "    KNNFeatureExpert,\n",
    "    RFFeatureExpert,\n",
    "    SVMFeatureExpert\n",
    "]\n",
    "\n",
    "feature_experts = []\n",
    "for cls in feature_expert_classes:\n",
    "    expert = cls(dim=384)   # uses IPCA‐reduced 384‐dim by default\n",
    "    if not expert.model_path.exists():\n",
    "        print(f\"   * Fitting {cls.__name__} on IPCA‐384 features…\")\n",
    "        t0 = time.time()\n",
    "        expert.fit(train_df, y_tr)\n",
    "        elapsed = time.time() - t0\n",
    "        print(f\"     -> {cls.__name__} trained in {elapsed:.1f}s.\")\n",
    "        log_event(\n",
    "            LogKind.MODEL,\n",
    "            model=cls.__name__,\n",
    "            phase=\"fit\",\n",
    "            seconds=round(elapsed, 2),\n",
    "            src_dims=meta.shape[1]\n",
    "        )\n",
    "    else:\n",
    "        print(f\"   * {cls.__name__} pickle found—skipping training.\")\n",
    "        log_event(\n",
    "            LogKind.MODEL,\n",
    "            model=cls.__name__,\n",
    "            phase=\"load\",\n",
    "            seconds=0.0,\n",
    "            src_dims=meta.shape[1]\n",
    "        )\n",
    "    feature_experts.append(expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3542949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Initializing Hugging‐Face experts…\n",
      "   * Skipping XLNetExpert (sentencepiece not installed).\n",
      "   * QuoraDistilExpert LR already present—skipping LR training.\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 5) Load and configure pretrained experts\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n>>> Initializing Hugging‐Face experts…\")\n",
    "\n",
    "EMB_PATH = \"../data/processed/question_embeddings_768.npy\"\n",
    "LR_PATH  = PRETRAINED_DIR / \"quoradistil_lr.pkl\"\n",
    "\n",
    "hf_experts = [BertExpert(), RobertaExpert()]\n",
    "try:\n",
    "    xl = XLNetExpert()\n",
    "    hf_experts.append(xl)\n",
    "except RuntimeError:\n",
    "    print(\"   * Skipping XLNetExpert (sentencepiece not installed).\")\n",
    "\n",
    "quora_exp = QuoraDistilExpert(emb_path=EMB_PATH, lr_path=str(LR_PATH))\n",
    "hf_experts.append(quora_exp)\n",
    "hf_experts.append(CrossEncExpert())\n",
    "\n",
    "# Only fit QuoraDistilExpert’s LR head if pickle is missing\n",
    "if not quora_exp.lr_path.exists():\n",
    "    print(\"   * Training QuoraDistilExpert LR head on 768‐dim pairs…\")\n",
    "    t0 = time.time()\n",
    "    quora_exp.fit(\n",
    "        train_df.qid1.values.astype(int),\n",
    "        train_df.qid2.values.astype(int),\n",
    "        y_tr\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"     -> QuoraDistilExpert LR trained in {elapsed:.1f}s.\")\n",
    "    log_event(\n",
    "        LogKind.MODEL,\n",
    "        model=\"QuoraDistilExpert\",\n",
    "        phase=\"fit\",\n",
    "        seconds=round(elapsed, 2),\n",
    "        src_dims=1536\n",
    "    )\n",
    "else:\n",
    "    print(\"   * QuoraDistilExpert LR already present—skipping LR training.\")\n",
    "    log_event(\n",
    "        LogKind.MODEL,\n",
    "        model=\"QuoraDistilExpert\",\n",
    "        phase=\"load\",\n",
    "        seconds=0.0,\n",
    "        src_dims=1536\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da12ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total experts = 10\n",
      "   – BertExpert\n",
      "   – RobertaExpert\n",
      "   – QuoraDistilExpert\n",
      "   – CrossEncExpert\n",
      "   – LRFeatureExpert\n",
      "   – XGBFeatureExpert\n",
      "   – LGBMFeatureExpert\n",
      "   – KNNFeatureExpert\n",
      "   – RFFeatureExpert\n",
      "   – SVMFeatureExpert\n",
      "\n",
      ">>> Caching predictions for each expert…\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 6) Combine all experts & clean out any stale pred_cache files\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "experts = hf_experts + feature_experts\n",
    "print(f\"\\nTotal experts = {len(experts)}\\n   – \" +\n",
    "      \"\\n   – \".join([e.__class__.__name__ for e in experts]))\n",
    "\n",
    "def clean_cache_if_needed(pairs, split_tag):\n",
    "    \"\"\"\n",
    "    Delete any pred_cache/<split_tag>_*.npy whose row-count != len(pairs).\n",
    "    This prevents mismatched‐shape errors.\n",
    "    \"\"\"\n",
    "    for fpath in sorted(CACHE_DIR.glob(f\"{split_tag}_*.npy\")):\n",
    "        arr = np.load(fpath, mmap_mode=\"r\")\n",
    "        if arr.shape[0] != len(pairs):\n",
    "            print(f\"[WARNING] {fpath.name} has {arr.shape[0]} rows (expected {len(pairs)}). Deleting.\")\n",
    "            fpath.unlink()\n",
    "\n",
    "clean_cache_if_needed(pairs_tr, \"train\")\n",
    "clean_cache_if_needed(pairs_val, \"valid\")\n",
    "\n",
    "# Now that any bad files are deleted, we can safely (re)compute missing predictions\n",
    "print(\"\\n>>> Caching predictions for each expert…\")\n",
    "t0 = time.time()\n",
    "P_tr  = get_predictions(experts, pairs_tr,  \"train\", cache_dir=CACHE_DIR)\n",
    "P_val = get_predictions(experts, pairs_val, \"valid\", cache_dir=CACHE_DIR)\n",
    "elapsed = time.time() - t0\n",
    "print(f\"   * Forward‐passes & caching completed in {elapsed:.1f}s.\")\n",
    "print(f\"   * Shapes: P_tr={P_tr.shape}, P_val={P_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Starting gate tuning over VALID split…\n",
      "   * Evaluating 1023 distinct subsets…\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0,) (BertExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1084\n",
      "Epoch 2/2  ·  loss 0.1144\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1025\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1,) (RobertaExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2104\n",
      "Epoch 2/2  ·  loss 0.2433\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2393\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2,) (QuoraDistilExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0000\n",
      "Epoch 2/2  ·  loss 0.0000\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.8675\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3,) (CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.5918\n",
      "Epoch 2/2  ·  loss 0.5841\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6071\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (4,) (LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.6550\n",
      "Epoch 2/2  ·  loss 0.6548\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6556\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (5,) (XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.3103\n",
      "Epoch 2/2  ·  loss 0.2785\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2960\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (6,) (LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2672\n",
      "Epoch 2/2  ·  loss 0.2666\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6175\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (7,) (KNNFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0484\n",
      "Epoch 2/2  ·  loss 0.0805\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0571\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (8,) (RFFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.6269\n",
      "Epoch 2/2  ·  loss 0.6276\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6223\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (9,) (SVMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.5894\n",
      "Epoch 2/2  ·  loss 0.6000\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6090\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1) (BertExpert+RobertaExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1074\n",
      "Epoch 2/2  ·  loss 0.1298\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1016\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2) (BertExpert+QuoraDistilExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0012\n",
      "Epoch 2/2  ·  loss 0.0004\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.7555\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3) (BertExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1120\n",
      "Epoch 2/2  ·  loss 0.0974\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1042\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 4) (BertExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1122\n",
      "Epoch 2/2  ·  loss 0.0942\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1042\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 5) (BertExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0824\n",
      "Epoch 2/2  ·  loss 0.1116\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1031\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 6) (BertExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1079\n",
      "Epoch 2/2  ·  loss 0.0779\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1231\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 7) (BertExpert+KNNFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0376\n",
      "Epoch 2/2  ·  loss 0.0242\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0380\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 8) (BertExpert+RFFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0971\n",
      "Epoch 2/2  ·  loss 0.1006\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1038\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 9) (BertExpert+SVMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1143\n",
      "Epoch 2/2  ·  loss 0.1135\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1044\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2) (RobertaExpert+QuoraDistilExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0015\n",
      "Epoch 2/2  ·  loss 0.0006\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.7582\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3) (RobertaExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2236\n",
      "Epoch 2/2  ·  loss 0.1936\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2300\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 4) (RobertaExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2122\n",
      "Epoch 2/2  ·  loss 0.2278\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2310\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 5) (RobertaExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2018\n",
      "Epoch 2/2  ·  loss 0.2281\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2041\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 6) (RobertaExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1819\n",
      "Epoch 2/2  ·  loss 0.1888\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2640\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 7) (RobertaExpert+KNNFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0647\n",
      "Epoch 2/2  ·  loss 0.0406\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0397\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 8) (RobertaExpert+RFFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2124\n",
      "Epoch 2/2  ·  loss 0.2665\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2314\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 9) (RobertaExpert+SVMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2140\n",
      "Epoch 2/2  ·  loss 0.1772\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2300\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3) (QuoraDistilExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0067\n",
      "Epoch 2/2  ·  loss 0.0025\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.7610\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 4) (QuoraDistilExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0044\n",
      "Epoch 2/2  ·  loss 0.0016\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.7671\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 5) (QuoraDistilExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0023\n",
      "Epoch 2/2  ·  loss 0.0009\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.7667\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 6) (QuoraDistilExpert+LGBMFeatureExpert) -> training gate…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/build/python-pytorch/src/pytorch-opt-cuda/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/build/python-pytorch/src/pytorch-opt-cuda/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    106\u001b[39m moe = MoEClassifier(subset_exps, lr=\u001b[32m1e-2\u001b[39m, epochs=\u001b[32m2\u001b[39m)\n\u001b[32m    107\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m>> Subset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midxs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m+\u001b[39m\u001b[33m'\u001b[39m.join(subset_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) -> training gate…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m ll = \u001b[43mfit_gate_from_preds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmoe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_tr_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_val_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m train_time = time.time() - t1\n\u001b[32m    110\u001b[39m save_gate(moe, ckpt_path)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mfit_gate_from_preds\u001b[39m\u001b[34m(moe, P_tr_sub, y_tr, P_val_sub, y_val)\u001b[39m\n\u001b[32m     42\u001b[39m         loss.backward()\n\u001b[32m     43\u001b[39m         moe.opt.step()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m         epoch_loss = \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmoe.epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  ·  loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Compute validation log-loss\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 7) Gate tuning over VALID split\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "from src.pretrained_models import save_gate, load_gate, _subset_key\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def fit_gate_from_preds(\n",
    "    moe: MoEClassifier,\n",
    "    P_tr_sub: np.ndarray,\n",
    "    y_tr: np.ndarray,\n",
    "    P_val_sub: np.ndarray,\n",
    "    y_val: np.ndarray\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Train `moe.gate` for `moe.epochs` epochs on precomputed columns P_tr_sub,\n",
    "    then compute validation log-loss on P_val_sub.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    B = 1024\n",
    "\n",
    "    probs_tr   = torch.tensor(P_tr_sub, dtype=torch.float32).to(device)\n",
    "    targets_tr = torch.tensor(y_tr, dtype=torch.float32).to(device)\n",
    "\n",
    "    ds     = TensorDataset(probs_tr, targets_tr)\n",
    "    loader = DataLoader(ds, batch_size=B, shuffle=True)\n",
    "\n",
    "    for epoch in range(1, moe.epochs + 1):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_probs, batch_targets in loader:\n",
    "            weights = moe.gate(batch_probs)\n",
    "            blended = (weights * batch_probs).sum(dim=1)\n",
    "            loss    = moe.loss_fn(blended, batch_targets)\n",
    "\n",
    "            moe.opt.zero_grad()\n",
    "            loss.backward()\n",
    "            moe.opt.step()\n",
    "\n",
    "            epoch_loss = loss.item()\n",
    "        print(f\"Epoch {epoch}/{moe.epochs}  ·  loss {epoch_loss:.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        probs_val   = torch.tensor(P_val_sub, dtype=torch.float32).to(device)\n",
    "        weights_val = moe.gate(probs_val)\n",
    "        blended_val = (weights_val * probs_val).sum(dim=1)\n",
    "    return log_loss(y_val, blended_val.cpu().numpy())\n",
    "\n",
    "print(\"\\n>>> Starting gate tuning over VALID split…\")\n",
    "idx_of        = {e.__class__.__name__: i for i, e in enumerate(experts)}\n",
    "valid_subsets = []\n",
    "for k in range(1, len(idx_of) + 1):\n",
    "    for tpl in combinations(idx_of.values(), k):\n",
    "        valid_subsets.append(tpl)\n",
    "\n",
    "print(f\"   * Evaluating {len(valid_subsets)} distinct subsets…\\n\")\n",
    "\n",
    "best_ll, best_subset = 1e9, None\n",
    "best_moe = None\n",
    "subset_results = []\n",
    "\n",
    "for idxs in valid_subsets:\n",
    "    subset_exps  = [experts[i] for i in idxs]\n",
    "    subset_names = [e.__class__.__name__ for e in subset_exps]\n",
    "    key = _subset_key(subset_exps)\n",
    "    ckpt_path = GATE_DIR / f\"gate_{key}.pt\"\n",
    "\n",
    "    P_tr_sub  = P_tr[:, idxs]\n",
    "    P_val_sub = P_val[:, idxs]\n",
    "\n",
    "    start_all = time.time()\n",
    "    if ckpt_path.exists():\n",
    "        print(\"-\"*80)\n",
    "        t1 = time.time()\n",
    "        moe = load_gate(subset_exps, ckpt_path)\n",
    "        load_time = time.time() - t1\n",
    "        print(f\"\\n>> Subset {idxs} ({'+'.join(subset_names)}) → gate loaded in {load_time:.1f}s\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            probs_val = torch.tensor(P_val_sub, dtype=torch.float32).to(device)\n",
    "            weights_val = moe.gate(probs_val)\n",
    "            blended_val = (weights_val * probs_val).sum(dim=1)\n",
    "        ll = log_loss(y_val, blended_val.cpu().numpy())\n",
    "\n",
    "        log_event(\n",
    "            LogKind.GATE,\n",
    "            model=f\"Gate_{key}\",\n",
    "            phase=\"load\",\n",
    "            seconds=round(load_time, 2),\n",
    "            valid_log_loss=round(ll, 4)\n",
    "        )\n",
    "    else:\n",
    "        print(\"-\"*80)\n",
    "        t1 = time.time()\n",
    "        moe = MoEClassifier(subset_exps, lr=1e-2, epochs=2)\n",
    "        print(f\"\\n>> Subset {idxs} ({'+'.join(subset_names)}) → training gate…\")\n",
    "        ll = fit_gate_from_preds(moe, P_tr_sub, y_tr, P_val_sub, y_val)\n",
    "        train_time = time.time() - t1\n",
    "        save_gate(moe, ckpt_path)\n",
    "        print(f\"   → gate trained & cached in {train_time:.1f}s\")\n",
    "        print(\"-\"*80)\n",
    "        log_event(\n",
    "            LogKind.GATE,\n",
    "            model=f\"Gate_{key}\",\n",
    "            phase=\"fit\",\n",
    "            seconds=round(train_time, 2),\n",
    "            valid_log_loss=round(ll, 4)\n",
    "        )\n",
    "\n",
    "    print(f\"   valid log-loss = {ll:.4f}\\n\")\n",
    "    total_time = time.time() - start_all\n",
    "    subset_results.append((idxs, ll))\n",
    "\n",
    "    if ll < best_ll:\n",
    "        best_ll, best_subset = ll, idxs\n",
    "        best_moe = moe\n",
    "\n",
    "print(f\"\\n>>> BEST subset {best_subset}  ·  valid LL = {best_ll:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea3829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Starting gate tuning over VALID split…\n",
      "   * Evaluating 127 distinct subsets…\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0,) (BertExpert) -> gate loaded in 0.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1025\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1,) (RobertaExpert) -> gate loaded in 0.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2393\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2,) (QuoraDistilExpert) -> gate loaded in 0.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6071\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3,) (CrossEncExpert) -> gate loaded in 0.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6556\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (4,) (LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2880\n",
      "Epoch 2/2  ·  loss 0.2753\n",
      "   -> gate trained & cached in 2.2s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2960\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (5,) (XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0968\n",
      "Epoch 2/2  ·  loss 0.0298\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0571\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (6,) (LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.6007\n",
      "Epoch 2/2  ·  loss 0.6101\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6090\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1) (BertExpert+RobertaExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1061\n",
      "Epoch 2/2  ·  loss 0.1426\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1015\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2) (BertExpert+QuoraDistilExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1013\n",
      "Epoch 2/2  ·  loss 0.0953\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1046\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3) (BertExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1273\n",
      "Epoch 2/2  ·  loss 0.1041\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1038\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 4) (BertExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0784\n",
      "Epoch 2/2  ·  loss 0.1343\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1032\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 5) (BertExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0356\n",
      "Epoch 2/2  ·  loss 0.0390\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0380\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 6) (BertExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0952\n",
      "Epoch 2/2  ·  loss 0.0972\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1044\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2) (RobertaExpert+QuoraDistilExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2010\n",
      "Epoch 2/2  ·  loss 0.2316\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2303\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3) (RobertaExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2379\n",
      "Epoch 2/2  ·  loss 0.2242\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2307\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 4) (RobertaExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2260\n",
      "Epoch 2/2  ·  loss 0.2258\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2041\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 5) (RobertaExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0372\n",
      "Epoch 2/2  ·  loss 0.0425\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0388\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 6) (RobertaExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2183\n",
      "Epoch 2/2  ·  loss 0.2089\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2304\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3) (QuoraDistilExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.5955\n",
      "Epoch 2/2  ·  loss 0.5992\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6070\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 4) (QuoraDistilExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2903\n",
      "Epoch 2/2  ·  loss 0.2795\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2973\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 5) (QuoraDistilExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0379\n",
      "Epoch 2/2  ·  loss 0.0490\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0444\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 6) (QuoraDistilExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.5800\n",
      "Epoch 2/2  ·  loss 0.5813\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6071\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 4) (CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2963\n",
      "Epoch 2/2  ·  loss 0.2868\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2968\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 5) (CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0445\n",
      "Epoch 2/2  ·  loss 0.0312\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0438\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 6) (CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.5955\n",
      "Epoch 2/2  ·  loss 0.5884\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6090\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (4, 5) (LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0443\n",
      "Epoch 2/2  ·  loss 0.0347\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0403\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (4, 6) (LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2953\n",
      "Epoch 2/2  ·  loss 0.2815\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2968\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (5, 6) (XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0536\n",
      "Epoch 2/2  ·  loss 0.0393\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0444\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2) (BertExpert+RobertaExpert+QuoraDistilExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0828\n",
      "Epoch 2/2  ·  loss 0.1246\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1031\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3) (BertExpert+RobertaExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1081\n",
      "Epoch 2/2  ·  loss 0.1059\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1029\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 4) (BertExpert+RobertaExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0938\n",
      "Epoch 2/2  ·  loss 0.1136\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1021\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 5) (BertExpert+RobertaExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0454\n",
      "Epoch 2/2  ·  loss 0.0337\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0370\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 6) (BertExpert+RobertaExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1176\n",
      "Epoch 2/2  ·  loss 0.0931\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1032\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3) (BertExpert+QuoraDistilExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1159\n",
      "Epoch 2/2  ·  loss 0.0981\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1042\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 4) (BertExpert+QuoraDistilExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1099\n",
      "Epoch 2/2  ·  loss 0.1088\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1039\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 5) (BertExpert+QuoraDistilExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0448\n",
      "Epoch 2/2  ·  loss 0.0321\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0386\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 6) (BertExpert+QuoraDistilExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0925\n",
      "Epoch 2/2  ·  loss 0.0919\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1043\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 4) (BertExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0955\n",
      "Epoch 2/2  ·  loss 0.0914\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1037\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 5) (BertExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0386\n",
      "Epoch 2/2  ·  loss 0.0555\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0385\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 6) (BertExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1150\n",
      "Epoch 2/2  ·  loss 0.1402\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1040\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 4, 5) (BertExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0391\n",
      "Epoch 2/2  ·  loss 0.0270\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0376\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 4, 6) (BertExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1002\n",
      "Epoch 2/2  ·  loss 0.0926\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1035\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 5, 6) (BertExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0459\n",
      "Epoch 2/2  ·  loss 0.0666\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0395\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3) (RobertaExpert+QuoraDistilExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2329\n",
      "Epoch 2/2  ·  loss 0.1877\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2306\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 4) (RobertaExpert+QuoraDistilExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2249\n",
      "Epoch 2/2  ·  loss 0.2153\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2054\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 5) (RobertaExpert+QuoraDistilExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0429\n",
      "Epoch 2/2  ·  loss 0.0619\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0404\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 6) (RobertaExpert+QuoraDistilExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2318\n",
      "Epoch 2/2  ·  loss 0.2604\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2312\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 4) (RobertaExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2134\n",
      "Epoch 2/2  ·  loss 0.2030\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2051\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 5) (RobertaExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0229\n",
      "Epoch 2/2  ·  loss 0.0479\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0399\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 6) (RobertaExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2064\n",
      "Epoch 2/2  ·  loss 0.2404\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2305\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 4, 5) (RobertaExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0343\n",
      "Epoch 2/2  ·  loss 0.0328\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0387\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 4, 6) (RobertaExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2197\n",
      "Epoch 2/2  ·  loss 0.2244\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2054\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 5, 6) (RobertaExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0529\n",
      "Epoch 2/2  ·  loss 0.0323\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0404\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 4) (QuoraDistilExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2851\n",
      "Epoch 2/2  ·  loss 0.2956\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2970\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 5) (QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0638\n",
      "Epoch 2/2  ·  loss 0.0367\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0451\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 6) (QuoraDistilExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.5761\n",
      "Epoch 2/2  ·  loss 0.5927\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6070\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 4, 5) (QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0472\n",
      "Epoch 2/2  ·  loss 0.0535\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0408\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 4, 6) (QuoraDistilExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2916\n",
      "Epoch 2/2  ·  loss 0.2862\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2973\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 5, 6) (QuoraDistilExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0548\n",
      "Epoch 2/2  ·  loss 0.0458\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0444\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 4, 5) (CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0369\n",
      "Epoch 2/2  ·  loss 0.0379\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0417\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 4, 6) (CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.3098\n",
      "Epoch 2/2  ·  loss 0.3047\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2972\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 5, 6) (CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0378\n",
      "Epoch 2/2  ·  loss 0.0415\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0453\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (4, 5, 6) (LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0454\n",
      "Epoch 2/2  ·  loss 0.0594\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0412\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1195\n",
      "Epoch 2/2  ·  loss 0.1044\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1031\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 4) (BertExpert+RobertaExpert+QuoraDistilExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1093\n",
      "Epoch 2/2  ·  loss 0.0658\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1028\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 5) (BertExpert+RobertaExpert+QuoraDistilExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0492\n",
      "Epoch 2/2  ·  loss 0.0440\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0375\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0721\n",
      "Epoch 2/2  ·  loss 0.1153\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1028\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 4) (BertExpert+RobertaExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1216\n",
      "Epoch 2/2  ·  loss 0.1073\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1026\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 5) (BertExpert+RobertaExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0571\n",
      "Epoch 2/2  ·  loss 0.0283\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0379\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 6) (BertExpert+RobertaExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1001\n",
      "Epoch 2/2  ·  loss 0.1006\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1030\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 4, 5) (BertExpert+RobertaExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0498\n",
      "Epoch 2/2  ·  loss 0.0319\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0374\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 4, 6) (BertExpert+RobertaExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1178\n",
      "Epoch 2/2  ·  loss 0.1035\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1024\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 5, 6) (BertExpert+RobertaExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0489\n",
      "Epoch 2/2  ·  loss 0.0249\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0379\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 4) (BertExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1379\n",
      "Epoch 2/2  ·  loss 0.1034\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1039\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 5) (BertExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0257\n",
      "Epoch 2/2  ·  loss 0.0177\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0396\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 6) (BertExpert+QuoraDistilExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1014\n",
      "Epoch 2/2  ·  loss 0.0908\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1044\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 4, 5) (BertExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0288\n",
      "Epoch 2/2  ·  loss 0.0471\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0383\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 4, 6) (BertExpert+QuoraDistilExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1184\n",
      "Epoch 2/2  ·  loss 0.0801\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1039\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 5, 6) (BertExpert+QuoraDistilExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0313\n",
      "Epoch 2/2  ·  loss 0.0387\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0388\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 4, 5) (BertExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0478\n",
      "Epoch 2/2  ·  loss 0.0441\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0393\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 4, 6) (BertExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0957\n",
      "Epoch 2/2  ·  loss 0.1116\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1039\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 5, 6) (BertExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0348\n",
      "Epoch 2/2  ·  loss 0.0497\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0389\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 4, 5, 6) (BertExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0514\n",
      "Epoch 2/2  ·  loss 0.0458\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0386\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 4) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2060\n",
      "Epoch 2/2  ·  loss 0.1797\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2057\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 5) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0451\n",
      "Epoch 2/2  ·  loss 0.0510\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0405\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 6) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2317\n",
      "Epoch 2/2  ·  loss 0.2654\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2317\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 4, 5) (RobertaExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0498\n",
      "Epoch 2/2  ·  loss 0.0567\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0403\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 4, 6) (RobertaExpert+QuoraDistilExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1993\n",
      "Epoch 2/2  ·  loss 0.1858\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2059\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 5, 6) (RobertaExpert+QuoraDistilExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0441\n",
      "Epoch 2/2  ·  loss 0.0726\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0404\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 4, 5) (RobertaExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0282\n",
      "Epoch 2/2  ·  loss 0.0373\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0392\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 4, 6) (RobertaExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1947\n",
      "Epoch 2/2  ·  loss 0.2130\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2054\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 5, 6) (RobertaExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0468\n",
      "Epoch 2/2  ·  loss 0.0178\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0409\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 4, 5, 6) (RobertaExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0363\n",
      "Epoch 2/2  ·  loss 0.0227\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0398\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 4, 5) (QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0489\n",
      "Epoch 2/2  ·  loss 0.0256\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0419\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 4, 6) (QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2765\n",
      "Epoch 2/2  ·  loss 0.2721\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2971\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 5, 6) (QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0514\n",
      "Epoch 2/2  ·  loss 0.0426\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0451\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 4, 5, 6) (QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0584\n",
      "Epoch 2/2  ·  loss 0.0453\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0413\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 4, 5, 6) (CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0420\n",
      "Epoch 2/2  ·  loss 0.0386\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0416\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 4) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1088\n",
      "Epoch 2/2  ·  loss 0.0729\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1031\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 5) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0293\n",
      "Epoch 2/2  ·  loss 0.0387\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0379\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1051\n",
      "Epoch 2/2  ·  loss 0.0841\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1030\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 4, 5) (BertExpert+RobertaExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0322\n",
      "Epoch 2/2  ·  loss 0.0226\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0379\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 4, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1098\n",
      "Epoch 2/2  ·  loss 0.0956\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1027\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 5, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0629\n",
      "Epoch 2/2  ·  loss 0.0225\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0380\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 4, 5) (BertExpert+RobertaExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0411\n",
      "Epoch 2/2  ·  loss 0.0473\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0384\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 4, 6) (BertExpert+RobertaExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0869\n",
      "Epoch 2/2  ·  loss 0.0950\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1029\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 5, 6) (BertExpert+RobertaExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0370\n",
      "Epoch 2/2  ·  loss 0.0200\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0379\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 4, 5, 6) (BertExpert+RobertaExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0283\n",
      "Epoch 2/2  ·  loss 0.0255\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0380\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 4, 5) (BertExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0466\n",
      "Epoch 2/2  ·  loss 0.0415\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0387\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 4, 6) (BertExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1116\n",
      "Epoch 2/2  ·  loss 0.1033\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1037\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 5, 6) (BertExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0570\n",
      "Epoch 2/2  ·  loss 0.0381\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0388\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 4, 5, 6) (BertExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0353\n",
      "Epoch 2/2  ·  loss 0.0396\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0389\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 4, 5, 6) (BertExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0371\n",
      "Epoch 2/2  ·  loss 0.0471\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0386\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 4, 5) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0340\n",
      "Epoch 2/2  ·  loss 0.0440\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0408\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 4, 6) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2071\n",
      "Epoch 2/2  ·  loss 0.1907\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2056\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 5, 6) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0352\n",
      "Epoch 2/2  ·  loss 0.0416\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0406\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 4, 5, 6) (RobertaExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0432\n",
      "Epoch 2/2  ·  loss 0.0542\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0400\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 4, 5, 6) (RobertaExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0364\n",
      "Epoch 2/2  ·  loss 0.0642\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0398\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 4, 5, 6) (QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0450\n",
      "Epoch 2/2  ·  loss 0.0391\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0416\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 4, 5) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0329\n",
      "Epoch 2/2  ·  loss 0.0406\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0385\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 4, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1005\n",
      "Epoch 2/2  ·  loss 0.1021\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1027\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 5, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0481\n",
      "Epoch 2/2  ·  loss 0.0447\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0380\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 4, 5, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0314\n",
      "Epoch 2/2  ·  loss 0.0401\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0382\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 4, 5, 6) (BertExpert+RobertaExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0444\n",
      "Epoch 2/2  ·  loss 0.0323\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0383\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 4, 5, 6) (BertExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0584\n",
      "Epoch 2/2  ·  loss 0.0586\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0387\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 4, 5, 6) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0499\n",
      "Epoch 2/2  ·  loss 0.0449\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0398\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 4, 5, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0305\n",
      "Epoch 2/2  ·  loss 0.0534\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0383\n",
      "\n",
      "\n",
      ">>> BEST subset (0, 1, 5)  ·  valid LL = 0.0370\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 8) Retrain TOP-10 gates on Train+Valid & save final checkpoints\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n>>> Retraining TOP-10 gates on Train+Valid…\")\n",
    "\n",
    "subset_results_sorted = sorted(subset_results, key=lambda x: x[1])[:10]\n",
    "\n",
    "P_tv = np.vstack([P_tr, P_val])\n",
    "y_tv = np.concatenate([y_tr, y_val])\n",
    "\n",
    "for rank, (idxs, ll_val) in enumerate(subset_results_sorted, start=1):\n",
    "    subset_exps  = [experts[i] for i in idxs]\n",
    "    subset_names = [e.__class__.__name__ for e in subset_exps]\n",
    "    key = _subset_key(subset_exps)\n",
    "    print(f\"\\n--- Retraining rank {rank} subset {idxs} ({'+'.join(subset_names)}) ---\")\n",
    "\n",
    "    P_tv_sub = P_tv[:, idxs]\n",
    "    t0 = time.time()\n",
    "    moe = MoEClassifier(subset_exps, lr=1e-2, epochs=2)\n",
    "    ll_tv = fit_gate_from_preds(\n",
    "        moe,\n",
    "        P_tr_sub=P_tv_sub[:len(y_tr)],\n",
    "        y_tr=y_tr,\n",
    "        P_val_sub=P_tv_sub[len(y_tr):],\n",
    "        y_val=y_val\n",
    "    )\n",
    "    elapsed_tv = time.time() - t0\n",
    "    print(f\"   → Gate for {key} retrained in {elapsed_tv:.1f}s · valid LL={ll_tv:.4f}\")\n",
    "\n",
    "    ckpt_path = GATE_DIR / f\"gate_{key}_retrained.pt\"\n",
    "    idx_path  = GATE_DIR / f\"moe_{key}_idxs.npy\"\n",
    "    moe.gate.eval()\n",
    "    torch.save(moe.gate.state_dict(), ckpt_path)\n",
    "    np.save(idx_path, np.array(idxs))\n",
    "    print(f\"   * Saved gate state → {ckpt_path}\")\n",
    "    print(f\"   * Saved selected indices → {idx_path}\")\n",
    "\n",
    "    log_event(\n",
    "        LogKind.GATE,\n",
    "        model=f\"FinalGate_{key}\",\n",
    "        phase=\"fit\",\n",
    "        seconds=round(elapsed_tv, 2),\n",
    "        valid_log_loss=round(ll_tv, 4)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
