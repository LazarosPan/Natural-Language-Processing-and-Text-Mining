{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9e4bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7234a15698d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────\n",
    "# 04_models.ipynb  ·  Mixture‐of‐Experts training & automated tuning\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# ── CELL 1 ───────────────────────────────────────────────────────────────────\n",
    "# 0) Ensure src/ is on PYTHONPATH\n",
    "%run setup.py\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 13\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081434f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Load train/valid splits\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "DATA_DIR = Path(\"../data/splits\")\n",
    "train_df = pd.read_csv(DATA_DIR / \"train.csv\").dropna(subset=[\"question1\", \"question2\"])\n",
    "valid_df = pd.read_csv(DATA_DIR / \"valid.csv\").dropna(subset=[\"question1\", \"question2\"])\n",
    "\n",
    "pairs_tr  = list(zip(train_df.question1, train_df.question2))\n",
    "y_tr      = train_df.is_duplicate.values.astype(int)\n",
    "pairs_val = list(zip(valid_df.question1, valid_df.question2))\n",
    "y_val     = valid_df.is_duplicate.values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Ensure necessary directories exist\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# pretrained models (e.g. QuoraDistilExpert's LR pickle)\n",
    "PRETRAINED_DIR = Path(\"../models/pretrained\")\n",
    "PRETRAINED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# custom models (feature-based pickles)\n",
    "CUSTOM_DIR = Path(\"../models/custom\")\n",
    "CUSTOM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# feature artifacts (TF-IDF & SVD pickles)\n",
    "FEATURES_DIR = Path(\"../models/features\")\n",
    "FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# MoE gate checkpoints\n",
    "GATE_DIR = Path(\"../models/gates\")\n",
    "GATE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Metric logs\n",
    "METRIC_LOGS = Path(\"../models/metric_logs.txt\")\n",
    "if not METRIC_LOGS.exists():\n",
    "    with open(METRIC_LOGS, \"w\") as f:\n",
    "        f.write(\"model_or_subset,\\tstatus,\\ttrain_or_load_time(s),\\tvalidation_time(s),\\tvalid_log_loss\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437514f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Import all experts\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "from src.pretrained_models import (\n",
    "    BertExpert,\n",
    "    RobertaExpert,\n",
    "    XLNetExpert,\n",
    "    QuoraDistilExpert,\n",
    "    CrossEncExpert,\n",
    "    MoEClassifier,\n",
    "    get_predictions,\n",
    ")\n",
    "from src.custom_models import (\n",
    "    LRFeatureExpert,\n",
    "    XGBFeatureExpert,\n",
    "    LGBMFeatureExpert,\n",
    "    KNNFeatureExpert,\n",
    "    RFFeatureExpert,\n",
    "    SVMFeatureExpert,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5437f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Initializing classical feature-based experts…\n",
      "   * LRFeatureExpert pickle found—skipping training.\n",
      "   * XGBFeatureExpert pickle found—skipping training.\n",
      "   * LGBMFeatureExpert pickle found—skipping training.\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Instantiate & (if needed) fit feature-based experts (with timing logs)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "print(\">>> Initializing classical feature-based experts…\")\n",
    "\n",
    "# 4a) Prepare a version of train_df with qid1/qid2 (for feature_experts.fit)\n",
    "meta = pd.read_csv(\"../data/processed/question_meta.csv\")\n",
    "rev  = {q: i for i, q in enumerate(meta.question)}\n",
    "train_df = train_df.assign(\n",
    "    qid1=lambda d: d.question1.map(rev).astype(int),\n",
    "    qid2=lambda d: d.question2.map(rev).astype(int),\n",
    ")\n",
    "\n",
    "# Helper to append a single line to metric_logs.txt\n",
    "def log_model_time(name: str, status: str,\n",
    "                   train_time: float,\n",
    "                   val_time: float = 0.0,\n",
    "                   val_ll: float = 0.0):\n",
    "    with open(METRIC_LOGS, \"a\") as f:\n",
    "        f.write(f\"{name},\\t{status},\\t{train_time:.1f},\\t{val_time:.1f},\\t{val_ll:.4f}\\n\")\n",
    "\n",
    "# ──────────────── FeatureExperts ────────────────\n",
    "\n",
    "# LRFeatureExpert\n",
    "lr_exp = LRFeatureExpert()\n",
    "if not lr_exp.model_path.exists():\n",
    "    print(\"   * Fitting LRFeatureExpert on engineered features…\")\n",
    "    t0 = time.time()\n",
    "    lr_exp.fit(train_df, y_tr)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"     -> LRFeatureExpert trained in {elapsed:.1f}s.\")\n",
    "    log_model_time(\"LRFeatureExpert\", \"trained\", elapsed)\n",
    "else:\n",
    "    print(\"   * LRFeatureExpert pickle found—skipping training.\")\n",
    "    log_model_time(\"LRFeatureExpert\", \"loaded\", 0.0)\n",
    "\n",
    "# XGBFeatureExpert\n",
    "xgb_exp = XGBFeatureExpert()\n",
    "if not xgb_exp.model_path.exists():\n",
    "    print(\"   * Fitting XGBFeatureExpert on engineered features…\")\n",
    "    t0 = time.time()\n",
    "    xgb_exp.fit(train_df, y_tr)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"     -> XGBFeatureExpert trained in {elapsed:.1f}s.\")\n",
    "    log_model_time(\"XGBFeatureExpert\", \"trained\", elapsed)\n",
    "else:\n",
    "    print(\"   * XGBFeatureExpert pickle found—skipping training.\")\n",
    "    log_model_time(\"XGBFeatureExpert\", \"loaded\", 0.0)\n",
    "\n",
    "# LGBMFeatureExpert\n",
    "lgb_exp = LGBMFeatureExpert()\n",
    "if not lgb_exp.model_path.exists():\n",
    "    print(\"   * Fitting LGBMFeatureExpert on engineered features…\")\n",
    "    t0 = time.time()\n",
    "    lgb_exp.fit(train_df, y_tr)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"     -> LGBMFeatureExpert trained in {elapsed:.1f}s.\")\n",
    "    log_model_time(\"LGBMFeatureExpert\", \"trained\", elapsed)\n",
    "else:\n",
    "    print(\"   * LGBMFeatureExpert pickle found—skipping training.\")\n",
    "    log_model_time(\"LGBMFeatureExpert\", \"loaded\", 0.0)\n",
    "\n",
    "# KNNFeatureExpert\n",
    "knn_exp = KNNFeatureExpert()\n",
    "if not knn_exp.model_path.exists():\n",
    "    print(\"   * Fitting KNNFeatureExpert on engineered features…\")\n",
    "    t0 = time.time()\n",
    "    knn_exp.fit(train_df, y_tr)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"     -> KNNFeatureExpert trained in {elapsed:.1f}s.\")\n",
    "    log_model_time(\"KNNFeatureExpert\", \"trained\", elapsed)\n",
    "else:\n",
    "    print(\"   * KNNFeatureExpert pickle found—skipping training.\")\n",
    "    log_model_time(\"KNNFeatureExpert\", \"loaded\", 0.0)\n",
    "\n",
    "# RFFeatureExpert\n",
    "rf_exp = RFFeatureExpert()\n",
    "if not rf_exp.model_path.exists():\n",
    "    print(\"   * Fitting RFFeatureExpert on engineered features…\")\n",
    "    t0 = time.time()\n",
    "    rf_exp.fit(train_df, y_tr)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"     -> RFFeatureExpert trained in {elapsed:.1f}s.\")\n",
    "    log_model_time(\"RFFeatureExpert\", \"trained\", elapsed)\n",
    "else:\n",
    "    print(\"   * RFFeatureExpert pickle found—skipping training.\")\n",
    "    log_model_time(\"RFFeatureExpert\", \"loaded\", 0.0)\n",
    "\n",
    "# SVMFeatureExpert\n",
    "svm_exp = SVMFeatureExpert()\n",
    "if not svm_exp.model_path.exists():\n",
    "    print(\"   * Fitting SVMFeatureExpert on engineered features…\")\n",
    "    t0 = time.time()\n",
    "    svm_exp.fit(train_df, y_tr)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"     -> SVMFeatureExpert trained in {elapsed:.1f}s.\")\n",
    "    log_model_time(\"SVMFeatureExpert\", \"trained\", elapsed)\n",
    "else:\n",
    "    print(\"   * SVMFeatureExpert pickle found—skipping training.\")\n",
    "    log_model_time(\"SVMFeatureExpert\", \"loaded\", 0.0)\n",
    "\n",
    "# ─── Pretrained HF Expert QuoraDistilExpert (logistic-regression training) ───\n",
    "\n",
    "print(\"\\n>>> Initializing Hugging-Face experts…\")\n",
    "\n",
    "EMB_PATH = \"../data/processed/question_embeddings.npy\"\n",
    "LR_PATH  = PRETRAINED_DIR / \"quoradistil_lr.pkl\"\n",
    "\n",
    "hf_experts = [BertExpert(), RobertaExpert()]\n",
    "try:\n",
    "    xl = XLNetExpert()\n",
    "    hf_experts.append(xl)\n",
    "except RuntimeError:\n",
    "    print(\"   * Skipping XLNetExpert (sentencepiece not installed).\")\n",
    "\n",
    "# QuoraDistilExpert (only this one “trains” an LR head)\n",
    "quora_exp = QuoraDistilExpert(\n",
    "    emb_path=EMB_PATH,\n",
    "    lr_path=str(LR_PATH),\n",
    ")\n",
    "hf_experts.append(quora_exp)\n",
    "\n",
    "# CrossEncExpert (only loaded, no additional training)\n",
    "cross_exp = CrossEncExpert()\n",
    "hf_experts.append(cross_exp)\n",
    "\n",
    "print(f\"   * HF experts = {[e.__class__.__name__ for e in hf_experts]}\")\n",
    "\n",
    "# Train QuoraDistilExpert’s LR if missing\n",
    "if not quora_exp.lr_path.exists():\n",
    "    print(\"   * QuoraDistilExpert LR not found; training fresh LogisticRegression…\")\n",
    "    t0 = time.time()\n",
    "    quora_exp.fit(\n",
    "        train_df.qid1.values.astype(int),\n",
    "        train_df.qid2.values.astype(int),\n",
    "        y_tr\n",
    "    )\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"     -> QuoraDistilExpert LR trained in {elapsed:.1f}s.\")\n",
    "    log_model_time(\"QuoraDistilExpert\", \"trained\", elapsed)\n",
    "else:\n",
    "    print(\"   * QuoraDistilExpert LR already present—skipping LR training.\")\n",
    "    log_model_time(\"QuoraDistilExpert\", \"loaded\", 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3542949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Initializing Hugging-Face experts…\n",
      "   * Skipping XLNetExpert (sentencepiece not installed).\n",
      "   * HF experts = ['BertExpert', 'RobertaExpert', 'QuoraDistilExpert', 'CrossEncExpert']\n",
      "   * QuoraDistilExpert LR already present—skipping LR training.\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 5) Combine all experts into one list\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "experts = hf_experts + [\n",
    "    lr_exp, xgb_exp, lgb_exp,\n",
    "    knn_exp, rf_exp, svm_exp\n",
    "]\n",
    "print(f\"\\nTotal experts = {len(experts)}:\")\n",
    "for e in experts:\n",
    "    print(\"   –\", e.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da12ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total experts = 7:\n",
      "   – BertExpert\n",
      "   – RobertaExpert\n",
      "   – QuoraDistilExpert\n",
      "   – CrossEncExpert\n",
      "   – LRFeatureExpert\n",
      "   – XGBFeatureExpert\n",
      "   – LGBMFeatureExpert\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 6) Pre-compute & cache expert outputs on train/valid (once per split)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "from sklearn.metrics import log_loss\n",
    "import glob\n",
    "\n",
    "# If all “train_<Expert>.npy” exist already, load them; otherwise run get_predictions(...)\n",
    "pred_files_tr = sorted(glob.glob(\"../models/pred_cache/train_*.npy\"))\n",
    "if len(pred_files_tr) == len(experts):\n",
    "    print(\"Loading cached P_tr & P_val (skipping forward-passes).\")\n",
    "    P_tr = np.column_stack([np.load(f, mmap_mode=\"r\") for f in pred_files_tr])\n",
    "    pred_files_val = sorted(glob.glob(\"../models/pred_cache/valid_*.npy\"))\n",
    "    P_val = np.column_stack([np.load(f, mmap_mode=\"r\") for f in pred_files_val])\n",
    "else:\n",
    "    print(\"\\n>>> Pre-computing predictions for each expert on train/valid splits…\")\n",
    "    t0 = time.time()\n",
    "    P_tr  = get_predictions(experts, pairs_tr,  \"train\")\n",
    "    P_val = get_predictions(experts, pairs_val, \"valid\")\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"   * Expert forward-passes cached in {elapsed:.1f}s.  Shapes: {P_tr.shape}, {P_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9154221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached P_tr & P_val (skipping forward‐passes).\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 7) Gate tuning over VALID split (using precomputed P_tr / P_val only)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "from src.pretrained_models import save_gate, load_gate, _subset_key\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def fit_gate_from_preds(\n",
    "    moe: MoEClassifier,\n",
    "    P_tr_sub: np.ndarray,\n",
    "    y_tr: np.ndarray,\n",
    "    P_val_sub: np.ndarray,\n",
    "    y_val: np.ndarray\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Train `moe.gate` for `moe.epochs` epochs on precomputed columns P_tr_sub,\n",
    "    then compute validation log-loss on P_val_sub.\n",
    "    Returns valid_log_loss.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    B = 1024  # gate batch size\n",
    "\n",
    "    # Convert to torch tensors once\n",
    "    probs_tr = torch.tensor(P_tr_sub, dtype=torch.float32).to(device)   # (n_train, k)\n",
    "    targets_tr = torch.tensor(y_tr, dtype=torch.float32).to(device)    # (n_train,)\n",
    "\n",
    "    # DataLoader to shuffle\n",
    "    ds = TensorDataset(probs_tr, targets_tr)\n",
    "    loader = DataLoader(ds, batch_size=B, shuffle=True)\n",
    "\n",
    "    # Train for moe.epochs\n",
    "    for epoch in range(1, moe.epochs + 1):\n",
    "        epoch_loss = 0.0\n",
    "        for batch_probs, batch_targets in loader:\n",
    "            # Gate forward\n",
    "            weights = moe.gate(batch_probs)             # (B, k)\n",
    "            blended = (weights * batch_probs).sum(dim=1) # (B,)\n",
    "            loss   = moe.loss_fn(blended, batch_targets)\n",
    "\n",
    "            moe.opt.zero_grad()\n",
    "            loss.backward()\n",
    "            moe.opt.step()\n",
    "\n",
    "            epoch_loss = loss.item()\n",
    "        print(f\"Epoch {epoch}/{moe.epochs}  ·  loss {epoch_loss:.4f}\")\n",
    "\n",
    "    # Compute validation log-loss\n",
    "    with torch.no_grad():\n",
    "        probs_val  = torch.tensor(P_val_sub, dtype=torch.float32).to(device)  # (n_valid, k)\n",
    "        weights_val = moe.gate(probs_val)                                     # (n_valid, k)\n",
    "        blended_val = (weights_val * probs_val).sum(dim=1)                    # (n_valid,)\n",
    "    valid_ll = log_loss(y_val, blended_val.cpu().numpy())\n",
    "    return valid_ll\n",
    "\n",
    "\n",
    "print(\"\\n>>> Starting gate tuning over VALID split…\")\n",
    "# Build all non-empty subsets of expert indices\n",
    "idx_of = {e.__class__.__name__: i for i, e in enumerate(experts)}\n",
    "valid_subsets = []\n",
    "for k in range(1, len(idx_of) + 1):\n",
    "    for tpl in combinations(idx_of.values(), k):\n",
    "        valid_subsets.append(tpl)\n",
    "\n",
    "print(f\"   * Evaluating {len(valid_subsets)} distinct subsets…\\n\")\n",
    "\n",
    "best_ll, best_subset = 1e9, None\n",
    "best_moe = None\n",
    "\n",
    "for idxs in valid_subsets:\n",
    "    subset_exps  = [experts[i] for i in idxs]\n",
    "    subset_names = [e.__class__.__name__ for e in subset_exps]\n",
    "    key = _subset_key(subset_exps)\n",
    "    ckpt_path = GATE_DIR / f\"gate_{key}.pt\"\n",
    "\n",
    "    # Extract only those K columns from precomputed P_tr / P_val\n",
    "    P_tr_sub  = P_tr[:, idxs]   # shape = (n_train, k)\n",
    "    P_val_sub = P_val[:, idxs]  # shape = (n_valid, k)\n",
    "\n",
    "    start_all = time.time()\n",
    "\n",
    "    if ckpt_path.exists():\n",
    "        # (a) load pre-trained gate\n",
    "        print(\"-\" * 80)\n",
    "        t1 = time.time()\n",
    "        moe = load_gate(subset_exps, ckpt_path)\n",
    "        load_time = time.time() - t1\n",
    "        status = \"loaded\"\n",
    "        print(f\"\\n>> Subset {idxs} ({'+'.join(subset_names)}) -> gate loaded in {load_time:.1f}s\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        # Evaluate validation log-loss from cached P_val_sub\n",
    "        with torch.no_grad():\n",
    "            device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            probs_val = torch.tensor(P_val_sub, dtype=torch.float32).to(device)\n",
    "            weights_val = moe.gate(probs_val)\n",
    "            blended_val = (weights_val * probs_val).sum(dim=1)\n",
    "        ll = log_loss(y_val, blended_val.cpu().numpy())\n",
    "\n",
    "        val_time = 0.0\n",
    "    else:\n",
    "        # (b) train a new gate (from precomputed columns only)\n",
    "        print(\"-\" * 80)\n",
    "        t1 = time.time()\n",
    "        moe = MoEClassifier(subset_exps, lr=1e-2, epochs=2)\n",
    "        print(f\"\\n>> Subset {idxs} ({'+'.join(subset_names)}) -> training gate…\")\n",
    "        ll = fit_gate_from_preds(moe, P_tr_sub, y_tr, P_val_sub, y_val)\n",
    "        train_time = time.time() - t1\n",
    "        save_gate(moe, ckpt_path)\n",
    "        status = \"trained\"\n",
    "        print(f\"   -> gate trained & cached in {train_time:.1f}s\")\n",
    "        print(\"-\" * 80)\n",
    "        val_time = 0.0\n",
    "\n",
    "    print(f\"   valid log-loss = {ll:.4f}\\n\")\n",
    "\n",
    "    # Write to metric_logs.txt\n",
    "    with open(METRIC_LOGS, \"a\") as f:\n",
    "        if status == \"loaded\":\n",
    "            f.write(f\"{key},\\tloaded,\\t{load_time:.1f},\\t{val_time:.1f},\\t{ll:.4f}\\n\")\n",
    "        else:\n",
    "            f.write(f\"{key},\\ttrained,\\t{train_time:.1f},\\t{val_time:.1f},\\t{ll:.4f}\\n\")\n",
    "\n",
    "    total_time = time.time() - start_all\n",
    "\n",
    "    # Track best subset\n",
    "    if ll < best_ll:\n",
    "        best_ll, best_subset = ll, idxs\n",
    "        best_moe = moe\n",
    "\n",
    "print(f\"\\n>>> BEST subset {best_subset}  ·  valid LL = {best_ll:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea3829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Starting gate tuning over VALID split…\n",
      "   * Evaluating 127 distinct subsets…\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0,) (BertExpert) -> gate loaded in 0.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1025\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1,) (RobertaExpert) -> gate loaded in 0.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2393\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2,) (QuoraDistilExpert) -> gate loaded in 0.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6071\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3,) (CrossEncExpert) -> gate loaded in 0.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6556\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (4,) (LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2880\n",
      "Epoch 2/2  ·  loss 0.2753\n",
      "   -> gate trained & cached in 2.2s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2960\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (5,) (XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0968\n",
      "Epoch 2/2  ·  loss 0.0298\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0571\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (6,) (LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.6007\n",
      "Epoch 2/2  ·  loss 0.6101\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6090\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1) (BertExpert+RobertaExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1061\n",
      "Epoch 2/2  ·  loss 0.1426\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1015\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2) (BertExpert+QuoraDistilExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1013\n",
      "Epoch 2/2  ·  loss 0.0953\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1046\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3) (BertExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1273\n",
      "Epoch 2/2  ·  loss 0.1041\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1038\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 4) (BertExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0784\n",
      "Epoch 2/2  ·  loss 0.1343\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1032\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 5) (BertExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0356\n",
      "Epoch 2/2  ·  loss 0.0390\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0380\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 6) (BertExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0952\n",
      "Epoch 2/2  ·  loss 0.0972\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1044\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2) (RobertaExpert+QuoraDistilExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2010\n",
      "Epoch 2/2  ·  loss 0.2316\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2303\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3) (RobertaExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2379\n",
      "Epoch 2/2  ·  loss 0.2242\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2307\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 4) (RobertaExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2260\n",
      "Epoch 2/2  ·  loss 0.2258\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2041\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 5) (RobertaExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0372\n",
      "Epoch 2/2  ·  loss 0.0425\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0388\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 6) (RobertaExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2183\n",
      "Epoch 2/2  ·  loss 0.2089\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2304\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3) (QuoraDistilExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.5955\n",
      "Epoch 2/2  ·  loss 0.5992\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6070\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 4) (QuoraDistilExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2903\n",
      "Epoch 2/2  ·  loss 0.2795\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2973\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 5) (QuoraDistilExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0379\n",
      "Epoch 2/2  ·  loss 0.0490\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0444\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 6) (QuoraDistilExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.5800\n",
      "Epoch 2/2  ·  loss 0.5813\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6071\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 4) (CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2963\n",
      "Epoch 2/2  ·  loss 0.2868\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2968\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 5) (CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0445\n",
      "Epoch 2/2  ·  loss 0.0312\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0438\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 6) (CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.5955\n",
      "Epoch 2/2  ·  loss 0.5884\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6090\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (4, 5) (LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0443\n",
      "Epoch 2/2  ·  loss 0.0347\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0403\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (4, 6) (LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2953\n",
      "Epoch 2/2  ·  loss 0.2815\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2968\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (5, 6) (XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0536\n",
      "Epoch 2/2  ·  loss 0.0393\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0444\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2) (BertExpert+RobertaExpert+QuoraDistilExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0828\n",
      "Epoch 2/2  ·  loss 0.1246\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1031\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3) (BertExpert+RobertaExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1081\n",
      "Epoch 2/2  ·  loss 0.1059\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1029\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 4) (BertExpert+RobertaExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0938\n",
      "Epoch 2/2  ·  loss 0.1136\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1021\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 5) (BertExpert+RobertaExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0454\n",
      "Epoch 2/2  ·  loss 0.0337\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0370\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 6) (BertExpert+RobertaExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1176\n",
      "Epoch 2/2  ·  loss 0.0931\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1032\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3) (BertExpert+QuoraDistilExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1159\n",
      "Epoch 2/2  ·  loss 0.0981\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1042\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 4) (BertExpert+QuoraDistilExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1099\n",
      "Epoch 2/2  ·  loss 0.1088\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1039\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 5) (BertExpert+QuoraDistilExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0448\n",
      "Epoch 2/2  ·  loss 0.0321\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0386\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 6) (BertExpert+QuoraDistilExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0925\n",
      "Epoch 2/2  ·  loss 0.0919\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1043\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 4) (BertExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0955\n",
      "Epoch 2/2  ·  loss 0.0914\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1037\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 5) (BertExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0386\n",
      "Epoch 2/2  ·  loss 0.0555\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0385\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 6) (BertExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1150\n",
      "Epoch 2/2  ·  loss 0.1402\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1040\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 4, 5) (BertExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0391\n",
      "Epoch 2/2  ·  loss 0.0270\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0376\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 4, 6) (BertExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1002\n",
      "Epoch 2/2  ·  loss 0.0926\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1035\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 5, 6) (BertExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0459\n",
      "Epoch 2/2  ·  loss 0.0666\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0395\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3) (RobertaExpert+QuoraDistilExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2329\n",
      "Epoch 2/2  ·  loss 0.1877\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2306\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 4) (RobertaExpert+QuoraDistilExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2249\n",
      "Epoch 2/2  ·  loss 0.2153\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2054\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 5) (RobertaExpert+QuoraDistilExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0429\n",
      "Epoch 2/2  ·  loss 0.0619\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0404\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 6) (RobertaExpert+QuoraDistilExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2318\n",
      "Epoch 2/2  ·  loss 0.2604\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2312\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 4) (RobertaExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2134\n",
      "Epoch 2/2  ·  loss 0.2030\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2051\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 5) (RobertaExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0229\n",
      "Epoch 2/2  ·  loss 0.0479\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0399\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 6) (RobertaExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2064\n",
      "Epoch 2/2  ·  loss 0.2404\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2305\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 4, 5) (RobertaExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0343\n",
      "Epoch 2/2  ·  loss 0.0328\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0387\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 4, 6) (RobertaExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2197\n",
      "Epoch 2/2  ·  loss 0.2244\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2054\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 5, 6) (RobertaExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0529\n",
      "Epoch 2/2  ·  loss 0.0323\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0404\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 4) (QuoraDistilExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2851\n",
      "Epoch 2/2  ·  loss 0.2956\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2970\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 5) (QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0638\n",
      "Epoch 2/2  ·  loss 0.0367\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0451\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 6) (QuoraDistilExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.5761\n",
      "Epoch 2/2  ·  loss 0.5927\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.6070\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 4, 5) (QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0472\n",
      "Epoch 2/2  ·  loss 0.0535\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0408\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 4, 6) (QuoraDistilExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2916\n",
      "Epoch 2/2  ·  loss 0.2862\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2973\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 5, 6) (QuoraDistilExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0548\n",
      "Epoch 2/2  ·  loss 0.0458\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0444\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 4, 5) (CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0369\n",
      "Epoch 2/2  ·  loss 0.0379\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0417\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 4, 6) (CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.3098\n",
      "Epoch 2/2  ·  loss 0.3047\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2972\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 5, 6) (CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0378\n",
      "Epoch 2/2  ·  loss 0.0415\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0453\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (4, 5, 6) (LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0454\n",
      "Epoch 2/2  ·  loss 0.0594\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0412\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1195\n",
      "Epoch 2/2  ·  loss 0.1044\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1031\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 4) (BertExpert+RobertaExpert+QuoraDistilExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1093\n",
      "Epoch 2/2  ·  loss 0.0658\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1028\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 5) (BertExpert+RobertaExpert+QuoraDistilExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0492\n",
      "Epoch 2/2  ·  loss 0.0440\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0375\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0721\n",
      "Epoch 2/2  ·  loss 0.1153\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1028\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 4) (BertExpert+RobertaExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1216\n",
      "Epoch 2/2  ·  loss 0.1073\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1026\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 5) (BertExpert+RobertaExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0571\n",
      "Epoch 2/2  ·  loss 0.0283\n",
      "   -> gate trained & cached in 2.1s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0379\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 6) (BertExpert+RobertaExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1001\n",
      "Epoch 2/2  ·  loss 0.1006\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1030\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 4, 5) (BertExpert+RobertaExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0498\n",
      "Epoch 2/2  ·  loss 0.0319\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0374\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 4, 6) (BertExpert+RobertaExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1178\n",
      "Epoch 2/2  ·  loss 0.1035\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1024\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 5, 6) (BertExpert+RobertaExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0489\n",
      "Epoch 2/2  ·  loss 0.0249\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0379\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 4) (BertExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1379\n",
      "Epoch 2/2  ·  loss 0.1034\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1039\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 5) (BertExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0257\n",
      "Epoch 2/2  ·  loss 0.0177\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0396\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 6) (BertExpert+QuoraDistilExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1014\n",
      "Epoch 2/2  ·  loss 0.0908\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1044\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 4, 5) (BertExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0288\n",
      "Epoch 2/2  ·  loss 0.0471\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0383\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 4, 6) (BertExpert+QuoraDistilExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1184\n",
      "Epoch 2/2  ·  loss 0.0801\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1039\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 5, 6) (BertExpert+QuoraDistilExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0313\n",
      "Epoch 2/2  ·  loss 0.0387\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0388\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 4, 5) (BertExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0478\n",
      "Epoch 2/2  ·  loss 0.0441\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0393\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 4, 6) (BertExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0957\n",
      "Epoch 2/2  ·  loss 0.1116\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1039\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 5, 6) (BertExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0348\n",
      "Epoch 2/2  ·  loss 0.0497\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0389\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 4, 5, 6) (BertExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0514\n",
      "Epoch 2/2  ·  loss 0.0458\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0386\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 4) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2060\n",
      "Epoch 2/2  ·  loss 0.1797\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2057\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 5) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0451\n",
      "Epoch 2/2  ·  loss 0.0510\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0405\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 6) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2317\n",
      "Epoch 2/2  ·  loss 0.2654\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2317\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 4, 5) (RobertaExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0498\n",
      "Epoch 2/2  ·  loss 0.0567\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0403\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 4, 6) (RobertaExpert+QuoraDistilExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1993\n",
      "Epoch 2/2  ·  loss 0.1858\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2059\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 5, 6) (RobertaExpert+QuoraDistilExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0441\n",
      "Epoch 2/2  ·  loss 0.0726\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0404\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 4, 5) (RobertaExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0282\n",
      "Epoch 2/2  ·  loss 0.0373\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0392\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 4, 6) (RobertaExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1947\n",
      "Epoch 2/2  ·  loss 0.2130\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2054\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 5, 6) (RobertaExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0468\n",
      "Epoch 2/2  ·  loss 0.0178\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0409\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 4, 5, 6) (RobertaExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0363\n",
      "Epoch 2/2  ·  loss 0.0227\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0398\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 4, 5) (QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0489\n",
      "Epoch 2/2  ·  loss 0.0256\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0419\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 4, 6) (QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2765\n",
      "Epoch 2/2  ·  loss 0.2721\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2971\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 5, 6) (QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0514\n",
      "Epoch 2/2  ·  loss 0.0426\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0451\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 4, 5, 6) (QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0584\n",
      "Epoch 2/2  ·  loss 0.0453\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0413\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (3, 4, 5, 6) (CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0420\n",
      "Epoch 2/2  ·  loss 0.0386\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0416\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 4) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1088\n",
      "Epoch 2/2  ·  loss 0.0729\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1031\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 5) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0293\n",
      "Epoch 2/2  ·  loss 0.0387\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0379\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1051\n",
      "Epoch 2/2  ·  loss 0.0841\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1030\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 4, 5) (BertExpert+RobertaExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0322\n",
      "Epoch 2/2  ·  loss 0.0226\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0379\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 4, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1098\n",
      "Epoch 2/2  ·  loss 0.0956\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1027\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 5, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0629\n",
      "Epoch 2/2  ·  loss 0.0225\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0380\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 4, 5) (BertExpert+RobertaExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0411\n",
      "Epoch 2/2  ·  loss 0.0473\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0384\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 4, 6) (BertExpert+RobertaExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0869\n",
      "Epoch 2/2  ·  loss 0.0950\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1029\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 5, 6) (BertExpert+RobertaExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0370\n",
      "Epoch 2/2  ·  loss 0.0200\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0379\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 4, 5, 6) (BertExpert+RobertaExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0283\n",
      "Epoch 2/2  ·  loss 0.0255\n",
      "   -> gate trained & cached in 1.9s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0380\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 4, 5) (BertExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0466\n",
      "Epoch 2/2  ·  loss 0.0415\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0387\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 4, 6) (BertExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1116\n",
      "Epoch 2/2  ·  loss 0.1033\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1037\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 5, 6) (BertExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0570\n",
      "Epoch 2/2  ·  loss 0.0381\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0388\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 4, 5, 6) (BertExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0353\n",
      "Epoch 2/2  ·  loss 0.0396\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0389\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 3, 4, 5, 6) (BertExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0371\n",
      "Epoch 2/2  ·  loss 0.0471\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0386\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 4, 5) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0340\n",
      "Epoch 2/2  ·  loss 0.0440\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0408\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 4, 6) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.2071\n",
      "Epoch 2/2  ·  loss 0.1907\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.2056\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 5, 6) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0352\n",
      "Epoch 2/2  ·  loss 0.0416\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0406\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 4, 5, 6) (RobertaExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0432\n",
      "Epoch 2/2  ·  loss 0.0542\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0400\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 3, 4, 5, 6) (RobertaExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0364\n",
      "Epoch 2/2  ·  loss 0.0642\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0398\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (2, 3, 4, 5, 6) (QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0450\n",
      "Epoch 2/2  ·  loss 0.0391\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0416\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 4, 5) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0329\n",
      "Epoch 2/2  ·  loss 0.0406\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0385\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 4, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.1005\n",
      "Epoch 2/2  ·  loss 0.1021\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.1027\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 5, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0481\n",
      "Epoch 2/2  ·  loss 0.0447\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0380\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 4, 5, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0314\n",
      "Epoch 2/2  ·  loss 0.0401\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0382\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 3, 4, 5, 6) (BertExpert+RobertaExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0444\n",
      "Epoch 2/2  ·  loss 0.0323\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0383\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 2, 3, 4, 5, 6) (BertExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0584\n",
      "Epoch 2/2  ·  loss 0.0586\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0387\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (1, 2, 3, 4, 5, 6) (RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0499\n",
      "Epoch 2/2  ·  loss 0.0449\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0398\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      ">> Subset (0, 1, 2, 3, 4, 5, 6) (BertExpert+RobertaExpert+QuoraDistilExpert+CrossEncExpert+LRFeatureExpert+XGBFeatureExpert+LGBMFeatureExpert) -> training gate…\n",
      "Epoch 1/2  ·  loss 0.0305\n",
      "Epoch 2/2  ·  loss 0.0534\n",
      "   -> gate trained & cached in 2.0s\n",
      "--------------------------------------------------------------------------------\n",
      "   valid log-loss = 0.0383\n",
      "\n",
      "\n",
      ">>> BEST subset (0, 1, 5)  ·  valid LL = 0.0370\n"
     ]
    }
   ],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 8) Retrain BEST gate on Train+Valid & save final checkpoint\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n>>> Re-training best gate on Train+Valid…\")\n",
    "\n",
    "# Concatenate train & valid P-matrices\n",
    "P_tv = np.vstack([P_tr, P_val])  # shape = (n_train + n_valid, K_total)\n",
    "y_tv = np.concatenate([y_tr, y_val])\n",
    "\n",
    "idxs = best_subset\n",
    "best_names = [experts[i].__class__.__name__ for i in idxs]\n",
    "print(f\"   * Subset indices = {idxs} ({'+'.join(best_names)})\")\n",
    "\n",
    "# Extract only those best-columns:\n",
    "P_tv_sub = P_tv[:, idxs]\n",
    "\n",
    "# Retrain gate on all (train+valid) columns\n",
    "start_tv = time.time()\n",
    "final_gate = MoEClassifier([experts[i] for i in idxs], lr=1e-2, epochs=2)\n",
    "# Use the same fit function that takes precomputed columns\n",
    "ll_tv = fit_gate_from_preds(\n",
    "    final_gate,\n",
    "    P_tr_sub=np.vstack([P_tr[:, idxs], P_val[:, idxs]]),\n",
    "    y_tr=np.concatenate([y_tr, y_val]),\n",
    "    P_val_sub=P_tv_sub[-len(y_val):],  # last len(y_val) rows are the “valid” portion\n",
    "    y_val=y_tv[-len(y_val):]\n",
    ")\n",
    "elapsed_tv = time.time() - start_tv\n",
    "print(f\"   * Final gate retrained on Train+Valid in {elapsed_tv:.1f}s.\")\n",
    "\n",
    "# Save final gate state & selected indices\n",
    "CKPT     = GATE_DIR / \"final_moe_gate.pt\"\n",
    "IDX_FPATH = GATE_DIR / \"moe_selected_idxs.npy\"\n",
    "final_gate.gate.eval()\n",
    "torch.save(final_gate.gate.state_dict(), CKPT)\n",
    "np.save(IDX_FPATH, np.array(best_subset))\n",
    "print(f\"   * Saved gate state -> {CKPT}\")\n",
    "print(f\"   * Saved selected indices -> {IDX_FPATH}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
